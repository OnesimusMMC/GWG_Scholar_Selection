{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsA418XxQ1BWtahnsErR/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OnesimusMMC/GWG_Scholar_Selection/blob/main/Scholar_Selection_Agent_V1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Xvu5R1tSgk_",
        "outputId": "249ee975-895f-4b2e-b2d0-705af859fad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google-generativeai version: 0.8.4\n",
            "google-ai-generativelanguage version: 0.6.15\n",
            "Google Sheets API Authentication Successful.\n",
            "Gemini API Configured Successfully.\n",
            "Please upload the Excel file containing applicant data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-47c68892-5dbe-4a0d-9b01-337d889ae389\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-47c68892-5dbe-4a0d-9b01-337d889ae389\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 150_Grow_with_Google_Application_Spring_2025_1743351004 copy.xlsx to 150_Grow_with_Google_Application_Spring_2025_1743351004 copy.xlsx\n",
            "File '150_Grow_with_Google_Application_Spring_2025_1743351004 copy.xlsx' uploaded successfully.\n",
            "Successfully loaded data from '150_Grow_with_Google_Application_Spring_2025_1743351004 copy.xlsx'. Found 150 applicants.\n",
            "\n",
            "--- Starting Applicant Evaluation (Rate Limit: 15 calls / 60s pause) ---\n",
            "Evaluating applicant 1/150...\n",
            "Evaluating applicant 2/150...\n",
            "Evaluating applicant 3/150...\n",
            "Evaluating applicant 4/150...\n",
            "Evaluating applicant 5/150...\n",
            "Evaluating applicant 6/150...\n",
            "Evaluating applicant 7/150...\n",
            "Evaluating applicant 8/150...\n",
            "Evaluating applicant 9/150...\n",
            "Evaluating applicant 10/150...\n",
            "Evaluating applicant 11/150...\n",
            "Evaluating applicant 12/150...\n",
            "Evaluating applicant 13/150...\n",
            "Evaluating applicant 14/150...\n",
            "Evaluating applicant 15/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 16/150...\n",
            "Evaluating applicant 17/150...\n",
            "Evaluating applicant 18/150...\n",
            "Evaluating applicant 19/150...\n",
            "Evaluating applicant 20/150...\n",
            "Evaluating applicant 21/150...\n",
            "Evaluating applicant 22/150...\n",
            "Evaluating applicant 23/150...\n",
            "Evaluating applicant 24/150...\n",
            "Evaluating applicant 25/150...\n",
            "Evaluating applicant 26/150...\n",
            "Evaluating applicant 27/150...\n",
            "Evaluating applicant 28/150...\n",
            "Evaluating applicant 29/150...\n",
            "Evaluating applicant 30/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 31/150...\n",
            "Evaluating applicant 32/150...\n",
            "Evaluating applicant 33/150...\n",
            "Evaluating applicant 34/150...\n",
            "Evaluating applicant 35/150...\n",
            "Evaluating applicant 36/150...\n",
            "Evaluating applicant 37/150...\n",
            "Evaluating applicant 38/150...\n",
            "Evaluating applicant 39/150...\n",
            "Evaluating applicant 40/150...\n",
            "Evaluating applicant 41/150...\n",
            "Evaluating applicant 42/150...\n",
            "Evaluating applicant 43/150...\n",
            "Evaluating applicant 44/150...\n",
            "Evaluating applicant 45/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 46/150...\n",
            "Evaluating applicant 47/150...\n",
            "Evaluating applicant 48/150...\n",
            "Evaluating applicant 49/150...\n",
            "Evaluating applicant 50/150...\n",
            "Evaluating applicant 51/150...\n",
            "Evaluating applicant 52/150...\n",
            "Evaluating applicant 53/150...\n",
            "Evaluating applicant 54/150...\n",
            "Evaluating applicant 55/150...\n",
            "Evaluating applicant 56/150...\n",
            "Evaluating applicant 57/150...\n",
            "Evaluating applicant 58/150...\n",
            "Evaluating applicant 59/150...\n",
            "Evaluating applicant 60/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 61/150...\n",
            "Evaluating applicant 62/150...\n",
            "Evaluating applicant 63/150...\n",
            "Evaluating applicant 64/150...\n",
            "Evaluating applicant 65/150...\n",
            "Evaluating applicant 66/150...\n",
            "Evaluating applicant 67/150...\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "Info: Using initial score for Effort Demonstrated as adjusted was not found.\n",
            "Warning: Parsed Total Score (3) does not match calculated sum (7). Using calculated value.\n",
            "Evaluating applicant 68/150...\n",
            "Evaluating applicant 69/150...\n",
            "Evaluating applicant 70/150...\n",
            "Evaluating applicant 71/150...\n",
            "Evaluating applicant 72/150...\n",
            "Evaluating applicant 73/150...\n",
            "Info: Using initial score for Clarity of Career Goals as adjusted was not found.\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "Info: Using initial score for Effort Demonstrated as adjusted was not found.\n",
            "Info: Using initial score for Alignment with Program as adjusted was not found.\n",
            "Info: Using initial score for Total Score as adjusted was not found.\n",
            "Evaluating applicant 74/150...\n",
            "Evaluating applicant 75/150...\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 76/150...\n",
            "Evaluating applicant 77/150...\n",
            "Evaluating applicant 78/150...\n",
            "Evaluating applicant 79/150...\n",
            "Evaluating applicant 80/150...\n",
            "Info: Using initial score for Clarity of Career Goals as adjusted was not found.\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "Info: Using initial score for Effort Demonstrated as adjusted was not found.\n",
            "Info: Using initial score for Alignment with Program as adjusted was not found.\n",
            "Info: Using initial score for Total Score as adjusted was not found.\n",
            "Warning: Parsed Total Score (48) does not match calculated sum (38). Using calculated value.\n",
            "Evaluating applicant 81/150...\n",
            "Evaluating applicant 82/150...\n",
            "Evaluating applicant 83/150...\n",
            "Evaluating applicant 84/150...\n",
            "Evaluating applicant 85/150...\n",
            "Evaluating applicant 86/150...\n",
            "Info: Using initial score for Clarity of Career Goals as adjusted was not found.\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "Info: Using initial score for Effort Demonstrated as adjusted was not found.\n",
            "Info: Using initial score for Alignment with Program as adjusted was not found.\n",
            "Warning: Parsed Total Score (29) does not match calculated sum (45). Using calculated value.\n",
            "Evaluating applicant 87/150...\n",
            "Evaluating applicant 88/150...\n",
            "Evaluating applicant 89/150...\n",
            "Evaluating applicant 90/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 91/150...\n",
            "Evaluating applicant 92/150...\n",
            "Warning: Parsed Total Score (23) does not match calculated sum (13). Using calculated value.\n",
            "Evaluating applicant 93/150...\n",
            "Evaluating applicant 94/150...\n",
            "Evaluating applicant 95/150...\n",
            "Evaluating applicant 96/150...\n",
            "Evaluating applicant 97/150...\n",
            "Evaluating applicant 98/150...\n",
            "Evaluating applicant 99/150...\n",
            "Evaluating applicant 100/150...\n",
            "Evaluating applicant 101/150...\n",
            "Evaluating applicant 102/150...\n",
            "Evaluating applicant 103/150...\n",
            "Evaluating applicant 104/150...\n",
            "Evaluating applicant 105/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 106/150...\n",
            "Evaluating applicant 107/150...\n",
            "Evaluating applicant 108/150...\n",
            "Evaluating applicant 109/150...\n",
            "Evaluating applicant 110/150...\n",
            "Evaluating applicant 111/150...\n",
            "Evaluating applicant 112/150...\n",
            "Evaluating applicant 113/150...\n",
            "Evaluating applicant 114/150...\n",
            "Evaluating applicant 115/150...\n",
            "Evaluating applicant 116/150...\n",
            "Evaluating applicant 117/150...\n",
            "Evaluating applicant 118/150...\n",
            "Evaluating applicant 119/150...\n",
            "Evaluating applicant 120/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 121/150...\n",
            "Evaluating applicant 122/150...\n",
            "Evaluating applicant 123/150...\n",
            "Evaluating applicant 124/150...\n",
            "Evaluating applicant 125/150...\n",
            "Evaluating applicant 126/150...\n",
            "Evaluating applicant 127/150...\n",
            "Evaluating applicant 128/150...\n",
            "Evaluating applicant 129/150...\n",
            "Evaluating applicant 130/150...\n",
            "Info: Using initial score for Clarity of Career Goals as adjusted was not found.\n",
            "Info: Using initial score for Relevant Experience as adjusted was not found.\n",
            "Info: Using initial score for Effort Demonstrated as adjusted was not found.\n",
            "Info: Using initial score for Alignment with Program as adjusted was not found.\n",
            "Info: Using initial score for Total Score as adjusted was not found.\n",
            "Evaluating applicant 131/150...\n",
            "Evaluating applicant 132/150...\n",
            "Evaluating applicant 133/150...\n",
            "Evaluating applicant 134/150...\n",
            "Evaluating applicant 135/150...\n",
            "\n",
            "--- Reached rate limit (15 calls). Pausing for 60 seconds... ---\n",
            "\n",
            "--- Resuming evaluation... ---\n",
            "Evaluating applicant 136/150...\n",
            "Evaluating applicant 137/150...\n",
            "Evaluating applicant 138/150...\n",
            "Evaluating applicant 139/150...\n",
            "Evaluating applicant 140/150...\n",
            "Evaluating applicant 141/150...\n",
            "Evaluating applicant 142/150...\n",
            "Evaluating applicant 143/150...\n",
            "Evaluating applicant 144/150...\n",
            "Evaluating applicant 145/150...\n",
            "Evaluating applicant 146/150...\n",
            "Evaluating applicant 147/150...\n",
            "Evaluating applicant 148/150...\n",
            "Evaluating applicant 149/150...\n",
            "Evaluating applicant 150/150...\n",
            "\n",
            "--- Evaluation Complete ---\n",
            "Total time taken: 1074.57 seconds\n",
            "Processed 150 applicants.\n",
            "Successfully evaluated: 150\n",
            "Failed/Errored evaluations: 0\n",
            "\n",
            "Preparing data for Google Sheets...\n",
            "Creating Google Sheet named: 150_Grow_with_Google_Application_Spring_2025_1743351004 copy_20250413_223210_evaluated\n",
            "Updating Google Sheet...\n",
            "✅ Evaluation results successfully saved to Google Sheet:\n",
            "   ➡️ https://docs.google.com/spreadsheets/d/1SNb-jXlzI9Gl7TFn-jivLKNx3wQKPn6Futl9nQ2kVUM\n",
            "\n",
            "Saving results to Excel file: applicant_scores_20250413_223210.xlsx...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_26a2133f-284b-4371-96d7-306c4c281820\", \"applicant_scores_20250413_223210.xlsx\", 288795)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Evaluation results saved to applicant_scores_20250413_223210.xlsx and download initiated.\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import google.ai.generativelanguage\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gspread\n",
        "from datetime import datetime\n",
        "import time\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "import re  # Import the regular expression library\n",
        "import numpy as np # Import numpy for nan/inf handling\n",
        "from google.colab import userdata\n",
        "import gspread.exceptions # Import specific gspread exceptions\n",
        "\n",
        "print(f\"google-generativeai version: {google.generativeai.__version__}\")\n",
        "print(f\"google-ai-generativelanguage version: {google.ai.generativelanguage.__version__}\")\n",
        "\n",
        "# --- 1. Install Libraries (if not already installed in Colab) ---\n",
        "# !pip install pandas google-generativeai gspread google-auth-httplib2 tenacity numpy\n",
        "\n",
        "# --- 2. Authenticate Google Sheets API ---\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    print(\"Google Sheets API Authentication Successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during Google Sheets Authentication: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Set up Gemini API Key ---\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not GEMINI_API_KEY:\n",
        "        raise ValueError(\"GEMINI_API_KEY not found in Colab secrets.\")\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    # Using a specific model known for reliability, adjust if needed\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash-latest') # Changed model name for potential compatibility/updates\n",
        "    print(\"Gemini API Configured Successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up Gemini API: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 4. Prepare Excel Sheet (File Upload) ---\n",
        "print(\"Please upload the Excel file containing applicant data.\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded. Exiting.\")\n",
        "        exit()\n",
        "    EXCEL_FILE_PATH = next(iter(uploaded))\n",
        "    print(f\"File '{EXCEL_FILE_PATH}' uploaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during file upload: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "current_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Added time for uniqueness\n",
        "OUTPUT_EXCEL_PATH = f\"applicant_scores_{current_date}.xlsx\"\n",
        "base_name = os.path.splitext(EXCEL_FILE_PATH)[0]\n",
        "GOOGLE_SHEET_NAME = f\"{base_name}_{current_date}_evaluated\"\n",
        "\n",
        "# --- 5. Load Data from Excel ---\n",
        "try:\n",
        "    df = pd.read_excel(EXCEL_FILE_PATH)\n",
        "    print(f\"Successfully loaded data from '{EXCEL_FILE_PATH}'. Found {len(df)} applicants.\")\n",
        "    # Basic validation: Check if DataFrame is empty\n",
        "    if df.empty:\n",
        "        print(\"Warning: The uploaded Excel file is empty.\")\n",
        "    # Optional: Add checks for expected columns if known\n",
        "    # expected_cols = ['Name', 'Email', 'Application Text'] # Example\n",
        "    # if not all(col in df.columns for col in expected_cols):\n",
        "    #    print(f\"Warning: Expected columns ({expected_cols}) not found in the Excel file.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Excel file not found at {EXCEL_FILE_PATH}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data from Excel file: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- Define Evaluation Criteria and Scoring Guidelines ---\n",
        "evaluation_criteria = \"\"\"\n",
        "**Use Case:** To create a fair and transparent process for evaluating applicants based on their career stage, goals, and alignment with the organization's mission.\n",
        "\n",
        "**Key Levels:**\n",
        "Level A: Career changers and upskillers.\n",
        "Level B: Entry-level candidates and college students.\n",
        "Level C: Career professionals seeking certifications but lacking a clear path.\n",
        "Level D: Individuals submitting AI-generated applications with limited personalization.\n",
        "\n",
        "**Point-Based Evaluation System:**\n",
        "Each applicant is scored out of 50 points across four criteria:\n",
        "\n",
        "**Criteria** | **Max Points** | **Scoring Guidelines**\n",
        "---|---|---\n",
        "Grade like a highly rated professor\n",
        "Clarity of Career Goals | 15 | Clear and specific goals (13–15); Somewhat clear (10–12); Unclear or vague (0–9).\n",
        "Relevant Experience | 10 | Strong transferable skills (8–10); Some relevant experience (5–7); Minimal (0–4).\n",
        "Effort Demonstrated | 15 | Evidence of upskilling or proactive learning (13–15); Moderate effort (5–12); None (0–4).\n",
        "Alignment with Program | 10 | Goals align with mentorship mission (8–10); Partial alignment (3–7); Misaligned (0–2).\n",
        "\n",
        "**Score Range and Decision:**\n",
        "40–50: Fully Accepted (Priority Placement).\n",
        "30–39: Accepted (Standard Placement).\n",
        "20–29: Waitlisted (Consider for Mentorship).\n",
        "0-19: Rejected (Not suitable for program at this time). # Added Rejected category for clarity\n",
        "\n",
        "**AI Detection Penalties:**\n",
        "- If 71-100% sure AI-generated: Reduce Clarity by 5, Effort by 5, Experience by 3, Alignment by 3.\n",
        "- If 60-70% sure AI-generated: Reduce Clarity by 4, Effort by 4, Experience by 2, Alignment by 2.\n",
        "-If 50-59% sure AI-generated: Reduce Clarity by 3, Effort by 3, Experience by 1, Alignment by 1.\n",
        "- If less than 50% sure AI-generated: No penalty.\n",
        "\"\"\"\n",
        "\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_fixed(20)) # Retry 3 times, wait 20s between attempts\n",
        "def evaluate_applicant(applicant_data):\n",
        "    \"\"\"Evaluates a single applicant using the Gemini API with retry logic.\"\"\"\n",
        "    prompt = f\"\"\"{evaluation_criteria}\n",
        "\n",
        "**Evaluate the following applicant based on the criteria above:**\n",
        "\n",
        "**Applicant Information:**\n",
        "{applicant_data}\n",
        "\n",
        "**Instructions:**\n",
        "1. Provide a score (0-Max Points) for each of the four criteria.\n",
        "2. Calculate the total score out of 50.\n",
        "3. Determine the final decision based on the total score (Fully Accepted, Accepted, Waitlisted, Rejected).\n",
        "4. Indicate if you detected potential AI generation (and the certainty level if applicable) BEFORE applying penalties.\n",
        "5. Apply penalties ONLY IF AI generation is detected based on the rules in the criteria. State the adjusted scores and the final decision AFTER penalties.\n",
        "6. Show the reason behind the scores in the console\n",
        "**Required Response Format:**\n",
        "AI Detection Certainty: [e.g., None, 65%, 80%]\n",
        "Clarity of Career Goals (Initial): [Score]/15\n",
        "Relevant Experience (Initial): [Score]/10\n",
        "Effort Demonstrated (Initial): [Score]/15\n",
        "Alignment with Program (Initial): [Score]/10\n",
        "Total Score (Initial): [Total Score]/50\n",
        "--- [Apply Penalties If Applicable] ---\n",
        "Clarity of Career Goals (Adjusted): [Score]/15\n",
        "Relevant Experience (Adjusted): [Score]/10\n",
        "Effort Demonstrated (Adjusted): [Score]/15\n",
        "Alignment with Program (Adjusted): [Score]/10\n",
        "Total Score (Adjusted): [Total Score]/50\n",
        "Final Decision: [Fully Accepted | Accepted | Waitlisted | Rejected]\n",
        "\"\"\"\n",
        "    try:\n",
        "        # It's often good to specify safety settings, especially when dealing with user-generated text\n",
        "        safety_settings = [\n",
        "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        ]\n",
        "        response = model.generate_content(prompt, safety_settings=safety_settings)\n",
        "        # Basic check if response has content\n",
        "        if response.parts:\n",
        "             return response.text\n",
        "        else:\n",
        "             # Handle cases where the response might be blocked or empty\n",
        "             print(f\"Warning: Received empty or blocked response from Gemini. Finish reason: {response.prompt_feedback.block_reason if response.prompt_feedback else 'N/A'}\")\n",
        "             return \"Error: Gemini response was empty or blocked.\"\n",
        "    except Exception as e:\n",
        "        # Catching potential API errors more specifically can be helpful\n",
        "        print(f\"Error during Gemini API call (will retry if possible): {e}\")\n",
        "        # Check for specific API-related errors if the library provides them\n",
        "        # Example: if isinstance(e, google.api_core.exceptions.ResourceExhausted): print(\"Rate limit likely exceeded.\")\n",
        "        raise  # Re-raise the exception for tenacity to handle retry\n",
        "\n",
        "\n",
        "# --- MODIFIED: parse_gemini_response ---\n",
        "def parse_gemini_response(response_text):\n",
        "    \"\"\"\n",
        "    Parses the Gemini API response to extract scores (initial and adjusted)\n",
        "    and decision using regular expressions. Returns final adjusted scores.\n",
        "    \"\"\"\n",
        "    # Initialize with None for robustness\n",
        "    scores = {\n",
        "        \"Clarity of Career Goals\": None,\n",
        "        \"Relevant Experience\": None,\n",
        "        \"Effort Demonstrated\": None,\n",
        "        \"Alignment with Program\": None,\n",
        "        \"Total Score\": None,\n",
        "    }\n",
        "    decision = \"Error: Parsing Failed\" # Default decision\n",
        "\n",
        "    # Prefer adjusted scores if available, otherwise fallback to initial\n",
        "    patterns = {\n",
        "        \"Clarity of Career Goals\": r\"Clarity of Career Goals \\(Adjusted\\):\\s*(\\d+)/15\",\n",
        "        \"Relevant Experience\": r\"Relevant Experience \\(Adjusted\\):\\s*(\\d+)/10\",\n",
        "        \"Effort Demonstrated\": r\"Effort Demonstrated \\(Adjusted\\):\\s*(\\d+)/15\",\n",
        "        \"Alignment with Program\": r\"Alignment with Program \\(Adjusted\\):\\s*(\\d+)/10\",\n",
        "        \"Total Score\": r\"Total Score \\(Adjusted\\):\\s*(\\d+)/50\",\n",
        "        # Fallback to initial scores if adjusted are not found\n",
        "        \"Clarity of Career Goals_Initial\": r\"Clarity of Career Goals \\(Initial\\):\\s*(\\d+)/15\",\n",
        "        \"Relevant Experience_Initial\": r\"Relevant Experience \\(Initial\\):\\s*(\\d+)/10\",\n",
        "        \"Effort Demonstrated_Initial\": r\"Effort Demonstrated \\(Initial\\):\\s*(\\d+)/15\",\n",
        "        \"Alignment with Program_Initial\": r\"Alignment with Program \\(Initial\\):\\s*(\\d+)/10\",\n",
        "        \"Total Score_Initial\": r\"Total Score \\(Initial\\):\\s*(\\d+)/50\",\n",
        "        \"Decision\": r\"Final Decision:\\s*(.+)\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Parse Decision first\n",
        "        decision_match = re.search(patterns[\"Decision\"], response_text, re.IGNORECASE | re.DOTALL)\n",
        "        if decision_match:\n",
        "            decision = decision_match.group(1).strip()\n",
        "        else:\n",
        "            print(f\"Warning: Could not parse Final Decision from response:\\n------\\n{response_text}\\n------\")\n",
        "            # Attempt to determine decision based on score if possible later\n",
        "\n",
        "        # Parse Scores (prioritize Adjusted)\n",
        "        for key in [\"Clarity of Career Goals\", \"Relevant Experience\", \"Effort Demonstrated\", \"Alignment with Program\", \"Total Score\"]:\n",
        "            adjusted_match = re.search(patterns[key], response_text, re.IGNORECASE)\n",
        "            if adjusted_match:\n",
        "                try:\n",
        "                    scores[key] = int(adjusted_match.group(1))\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Could not convert adjusted score to int for {key}.\")\n",
        "            else:\n",
        "                # If adjusted not found, try initial\n",
        "                initial_match = re.search(patterns[key + \"_Initial\"], response_text, re.IGNORECASE)\n",
        "                if initial_match:\n",
        "                    try:\n",
        "                        scores[key] = int(initial_match.group(1))\n",
        "                        print(f\"Info: Using initial score for {key} as adjusted was not found.\")\n",
        "                    except ValueError:\n",
        "                        print(f\"Warning: Could not convert initial score to int for {key}.\")\n",
        "                else:\n",
        "                     print(f\"Warning: Could not parse score (Adjusted or Initial) for {key}.\")\n",
        "                     # score[key] remains None\n",
        "\n",
        "        # Validate/Recalculate Total Score if needed\n",
        "        parsed_total = scores[\"Total Score\"]\n",
        "        individual_scores = [scores[\"Clarity of Career Goals\"], scores[\"Relevant Experience\"], scores[\"Effort Demonstrated\"], scores[\"Alignment with Program\"]]\n",
        "\n",
        "        if None not in individual_scores:\n",
        "             calculated_total = sum(individual_scores)\n",
        "             if parsed_total is None:\n",
        "                 scores[\"Total Score\"] = calculated_total\n",
        "                 print(f\"Info: Calculated Total Score as {calculated_total} (was missing).\")\n",
        "             elif parsed_total != calculated_total:\n",
        "                 print(f\"Warning: Parsed Total Score ({parsed_total}) does not match calculated sum ({calculated_total}). Using calculated value.\")\n",
        "                 scores[\"Total Score\"] = calculated_total\n",
        "        elif parsed_total is None:\n",
        "             print(\"Warning: Could not parse or calculate Total Score (missing individual scores).\")\n",
        "\n",
        "        # Fallback for decision if parsing failed but score exists\n",
        "        if decision == \"Error: Parsing Failed\" and scores[\"Total Score\"] is not None:\n",
        "            score = scores[\"Total Score\"]\n",
        "            if 40 <= score <= 50: decision = \"Fully Accepted\"\n",
        "            elif 30 <= score <= 39: decision = \"Accepted\"\n",
        "            elif 20 <= score <= 29: decision = \"Waitlisted\"\n",
        "            elif 0 <= score <= 19: decision = \"Rejected\"\n",
        "            else: decision = \"Error: Score out of range\"\n",
        "            print(f\"Info: Determined decision '{decision}' based on calculated/parsed score.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during response parsing: {e}\\nResponse Text:\\n------\\n{response_text}\\n------\")\n",
        "        # Return dict with Nones and default error decision\n",
        "        return {k: None for k in scores}, \"Error: Exception during Parsing\"\n",
        "\n",
        "    return scores, decision\n",
        "\n",
        "# --- 6. Iterate Through Applicants and Evaluate ---\n",
        "all_scores_list = [] # Use a list of dictionaries\n",
        "all_decisions = []\n",
        "raw_responses = []\n",
        "failed_applicants = []\n",
        "processed_count = 0\n",
        "# Consider making rate limit configurable or checking API documentation\n",
        "# Free tier is often 60 QPM (Queries Per Minute) -> 1 query per second\n",
        "# Pausing 60s after 15 calls is very conservative, could be faster e.g. 60s after 50 calls\n",
        "rate_limit_calls = 15 # Number of calls before pausing\n",
        "sleep_duration = 60 # Seconds to sleep (a bit more than 60s for safety)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(f\"\\n--- Starting Applicant Evaluation (Rate Limit: {rate_limit_calls} calls / {sleep_duration}s pause) ---\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Handle potential non-string data in rows before joining\n",
        "    try:\n",
        "        applicant_info = \"\\n\".join([f\"{col}: {str(row[col])}\" for col in df.columns if pd.notna(row[col])])\n",
        "    except Exception as e:\n",
        "        print(f\"Error formatting applicant info for row {index + 1}: {e}. Skipping applicant.\")\n",
        "        all_scores_list.append({}) # Append empty dict\n",
        "        all_decisions.append(\"Error: Formatting Applicant Info\")\n",
        "        raw_responses.append(\"Error formatting applicant data\")\n",
        "        failed_applicants.append((index, \"Error formatting applicant data\", str(e)))\n",
        "        continue # Skip to the next applicant\n",
        "\n",
        "    print(f\"Evaluating applicant {index + 1}/{len(df)}...\")\n",
        "\n",
        "    try:\n",
        "        gemini_response = evaluate_applicant(applicant_info)\n",
        "        raw_responses.append(gemini_response) # Store raw response regardless of parsing success\n",
        "\n",
        "        if \"Error: Gemini response was empty or blocked.\" in gemini_response:\n",
        "             scores = {k: None for k in [\"Clarity of Career Goals\", \"Relevant Experience\", \"Effort Demonstrated\", \"Alignment with Program\", \"Total Score\"]}\n",
        "             decision = \"Error: Gemini Response Blocked/Empty\"\n",
        "             print(f\"Failed processing applicant {index + 1} due to blocked/empty response.\")\n",
        "             failed_applicants.append((index, applicant_info, gemini_response))\n",
        "        elif gemini_response.startswith(\"Error:\"): # Catch other potential errors returned as strings\n",
        "             scores = {k: None for k in [\"Clarity of Career Goals\", \"Relevant Experience\", \"Effort Demonstrated\", \"Alignment with Program\", \"Total Score\"]}\n",
        "             decision = gemini_response # Store the specific error message\n",
        "             print(f\"Failed processing applicant {index + 1} due to Gemini error string: {decision}\")\n",
        "             failed_applicants.append((index, applicant_info, gemini_response))\n",
        "        else:\n",
        "            scores, decision = parse_gemini_response(gemini_response) # Parse the valid response\n",
        "\n",
        "        all_scores_list.append(scores)\n",
        "        all_decisions.append(decision)\n",
        "\n",
        "        # Optionally print parsed results for verification\n",
        "        # print(f\"  Parsed Scores: {scores}\")\n",
        "        # print(f\"  Decision: {decision}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # This catches errors from evaluate_applicant (after retries) or unexpected errors in the loop\n",
        "        print(f\"Failed to process applicant {index + 1} after retries or due to unexpected error: {e}\")\n",
        "        # Append placeholders\n",
        "        all_scores_list.append({k: None for k in [\"Clarity of Career Goals\", \"Relevant Experience\", \"Effort Demonstrated\", \"Alignment with Program\", \"Total Score\"]})\n",
        "        all_decisions.append(\"Error: Processing Failed\")\n",
        "        raw_responses.append(f\"Error during processing loop: {e}\")\n",
        "        failed_applicants.append((index, applicant_info, f\"API call/Loop failed: {e}\"))\n",
        "\n",
        "    processed_count += 1\n",
        "    # Rate Limiting Logic\n",
        "    if processed_count % rate_limit_calls == 0 and index < len(df) - 1:\n",
        "        print(f\"\\n--- Reached rate limit ({rate_limit_calls} calls). Pausing for {sleep_duration} seconds... ---\\n\")\n",
        "        time.sleep(sleep_duration)\n",
        "        print(\"--- Resuming evaluation... ---\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- Evaluation Complete ---\")\n",
        "print(f\"Total time taken: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Processed {processed_count} applicants.\")\n",
        "success_count = len([d for d in all_decisions if not d.startswith(\"Error:\")])\n",
        "print(f\"Successfully evaluated: {success_count}\")\n",
        "print(f\"Failed/Errored evaluations: {processed_count - success_count}\")\n",
        "\n",
        "# --- 7. Store and Output Results ---\n",
        "\n",
        "# Create DataFrame from the list of score dictionaries\n",
        "scores_df = pd.DataFrame(all_scores_list)\n",
        "\n",
        "# Define expected columns to ensure they exist, even if all parsing failed\n",
        "expected_score_cols = [\"Clarity of Career Goals\", \"Relevant Experience\", \"Effort Demonstrated\", \"Alignment with Program\", \"Total Score\"]\n",
        "for col in expected_score_cols:\n",
        "    if col not in scores_df.columns:\n",
        "        scores_df[col] = None # Add missing score columns initialized with None\n",
        "\n",
        "# Ensure correct column order and add Decision\n",
        "scores_df = scores_df[expected_score_cols]\n",
        "scores_df['Decision'] = all_decisions\n",
        "\n",
        "# Concatenate original data with scores and decisions\n",
        "# Reset index on both DataFrames before concat to ensure alignment\n",
        "df_reset = df.reset_index(drop=True)\n",
        "scores_df_reset = scores_df.reset_index(drop=True)\n",
        "final_df = pd.concat([df_reset, scores_df_reset], axis=1)\n",
        "\n",
        "# --- Output to Google Sheet ---\n",
        "try:\n",
        "    print(\"\\nPreparing data for Google Sheets...\")\n",
        "    # Replace NaN/NaT with empty strings, which are JSON compliant and show as blank cells\n",
        "    # Convert ALL data to strings before sending for maximum compatibility with gspread/JSON\n",
        "    final_df_str = final_df.fillna('').astype(str)\n",
        "\n",
        "    header = final_df_str.columns.tolist()\n",
        "    data = final_df_str.values.tolist()\n",
        "\n",
        "    print(f\"Creating Google Sheet named: {GOOGLE_SHEET_NAME}\")\n",
        "    spreadsheet = gc.create(GOOGLE_SHEET_NAME)\n",
        "    worksheet = spreadsheet.sheet1 # Get the first sheet\n",
        "\n",
        "    print(\"Updating Google Sheet...\")\n",
        "    # Use 'USER_ENTERED' to let Sheets interpret types if possible, though we send strings\n",
        "    worksheet.update([header] + data, value_input_option='USER_ENTERED')\n",
        "\n",
        "    # Share the sheet (optional, replace with your email or make public)\n",
        "    # spreadsheet.share('your_email@example.com', perm_type='user', role='writer')\n",
        "    # print(f\"Sharing Sheet with your_email@example.com\")\n",
        "\n",
        "    print(f\"✅ Evaluation results successfully saved to Google Sheet:\")\n",
        "    print(f\"   ➡️ {spreadsheet.url}\")\n",
        "\n",
        "except gspread.exceptions.APIError as e:\n",
        "     # Provide more specific feedback for API errors\n",
        "     print(f\"❌ Google Sheets API Error: {e}\")\n",
        "     print(\"   This might be due to permissions, quotas, or invalid data format.\")\n",
        "     print(\"   Check the full error message above and Google Cloud Console for details.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error saving results to Google Sheet: {e}\")\n",
        "    print(\"   Ensure Google Sheets API is enabled in your Google Cloud project.\")\n",
        "\n",
        "# --- Output to Downloadable Excel Sheet ---\n",
        "try:\n",
        "    print(f\"\\nSaving results to Excel file: {OUTPUT_EXCEL_PATH}...\")\n",
        "    # Fill NaN with empty strings for cleaner Excel output as well\n",
        "    final_df_excel = final_df.fillna('')\n",
        "    final_df_excel.to_excel(OUTPUT_EXCEL_PATH, index=False, engine='openpyxl') # Specify engine if needed\n",
        "    files.download(OUTPUT_EXCEL_PATH)\n",
        "    print(f\"✅ Evaluation results saved to {OUTPUT_EXCEL_PATH} and download initiated.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error saving results to Excel: {e}\")\n",
        "\n",
        "# --- Optional: Save failed responses ---\n",
        "if failed_applicants:\n",
        "    print(f\"\\nSaving details of {len(failed_applicants)} failed evaluations to 'failed_applicants.csv'...\")\n",
        "    try:\n",
        "        failed_df = pd.DataFrame(failed_applicants, columns=[\"Original Index\", \"Applicant Info Snippet\", \"Error/Raw Response\"])\n",
        "        # Truncate long applicant info/response for CSV readability\n",
        "        failed_df[\"Applicant Info Snippet\"] = failed_df[\"Applicant Info Snippet\"].str.slice(0, 500)\n",
        "        failed_df[\"Error/Raw Response\"] = failed_df[\"Error/Raw Response\"].str.slice(0, 1000)\n",
        "        failed_df.to_csv(\"failed_applicants.csv\", index=False)\n",
        "        print(\"✅ Saved failed applicant evaluations to 'failed_applicants.csv'\")\n",
        "        files.download(\"failed_applicants.csv\") # Also download the failed log\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving failed applicant log: {e}\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OUFbepjIhU58"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}